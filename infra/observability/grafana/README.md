# Observabilidade â€“ Monitoramento com Grafana ğŸ“Š

Este guia orienta como configurar o monitoramento local das 4 WebAPIs da AgroSolutions via Prometheus + Grafana (stack kubeâ€‘prometheusâ€‘stack), alÃ©m de validar se as mÃ©tricas estÃ£o chegando corretamente.

---

## âœ… PrÃ©â€‘requisitos

1) **Stack de Observabilidade instalada (Prometheus + Grafana)**

Se vocÃª seguiu o [Guia de ExecuÃ§Ã£o Kubernetes](../../k8s/README.md), o stack jÃ¡ deve estar instalado. Caso contrÃ¡rio:

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install kps prometheus-community/kube-prometheus-stack --namespace agrosolutions-observability --create-namespace
```

2) **APIs rodando no namespace local**

As 4 APIs devem estar em execuÃ§Ã£o no namespace `agrosolutions-local`:

```bash
kubectl get pods -n agrosolutions-local
```

---

## âœ… VerificaÃ§Ã£o de exposiÃ§Ã£o de mÃ©tricas

As APIs expÃµem mÃ©tricas em `/metrics` (OpenTelemetry/Prometheus). Para validar rapidamente:

```bash
kubectl port-forward svc/ingestao 8083:80 -n agrosolutions-local
```

Em outra janela:

```bash
curl http://localhost:8083/metrics
```

Repita para **analise**, **propriedades** e **usuarios** (alterando a porta local). Se houver saÃ­da de mÃ©tricas, o endpoint estÃ¡ OK.

---

## ğŸš€ CenÃ¡rio A â€” Ambiente Novo (subir o stack do zero)

1) **Instale o stack de observabilidade** (se ainda nÃ£o estiver):

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install kps prometheus-community/kube-prometheus-stack --namespace agrosolutions-observability --create-namespace
```

2) **Aplique os ServiceMonitors** (jÃ¡ incluÃ­dos no overlay local):

```bash
kubectl apply -k infra/k8s/overlays/local
```

3) **Acesse o Grafana**:

```bash
kubectl port-forward svc/kps-grafana 3000:80 -n agrosolutions-observability
```

URL: [http://localhost:3000](http://localhost:3000)

Credenciais padrÃ£o:
- UsuÃ¡rio: `admin`
- Senha: `prom-operator`

4) **Importe o dashboard padrÃ£o**:

- Arquivo: `infra/observability/grafana/dashboards/agrosolutions-apis-prometheus.json`
- Grafana â†’ **Dashboards** â†’ **New** â†’ **Import** â†’ **Upload dashboard JSON file**
- Selecione o DataSource `Prometheus` e clique em **Import**.

---

## ğŸš€ CenÃ¡rio B â€” Ambiente Existente (acesso e validaÃ§Ã£o)

1) **Acesse o Grafana**:

```bash
kubectl port-forward svc/kps-grafana 3000:80 -n agrosolutions-observability
```

2) **Verifique se as 4 APIs estÃ£o sendo trackeadas**:

- No Grafana, abra o dashboard **AgroSolutions â€” APIs (Prometheus)**.
- No painel **UP (Targets)**, devem aparecer 4 sÃ©ries: `analise`, `ingestao`, `propriedades`, `usuarios`.

3) **ValidaÃ§Ã£o via Prometheus (opcional)**:

```bash
kubectl port-forward svc/kps-kube-prometheus-stack-prometheus 9090:9090 -n agrosolutions-observability
```

Abra [http://localhost:9090](http://localhost:9090) e execute a query:

```
up{namespace="agrosolutions-local"}
```

Se vierem 4 targets com valor `1`, o scrape estÃ¡ OK.

---

## ğŸš€ CenÃ¡rio C â€” Reset de mÃ©tricas (sem perder dashboards)

Use quando quiser â€œlimparâ€ a sÃ©rie de mÃ©tricas coletadas sem apagar configuraÃ§Ãµes do Grafana.

1) **Reiniciar Prometheus e Grafana** (limpa caches e reabre conexÃµes):

```bash
kubectl rollout restart deployment/kps-grafana -n agrosolutions-observability
kubectl rollout restart statefulset/kps-kube-prometheus-stack-prometheus -n agrosolutions-observability
```

2) **Limpar dados do Prometheus (opcional)** â€” mantÃ©m dashboards do Grafana:

```bash
kubectl delete pvc -n agrosolutions-observability -l app.kubernetes.io/name=prometheus
kubectl rollout restart statefulset/kps-kube-prometheus-stack-prometheus -n agrosolutions-observability
```

> Isso zera o histÃ³rico de mÃ©tricas, mas preserva os dashboards (Grafana tem PVC separado).

---

## ğŸš€ CenÃ¡rio D â€” Hard Reset (remover e recriar todo o stack)

1) **Remover o stack de observabilidade**:

```bash
helm uninstall kps -n agrosolutions-observability
```

2) **Remover PVCs de Grafana e Prometheus**:

```bash
kubectl delete pvc -n agrosolutions-observability --all
```

3) **Recriar tudo**: volte ao **CenÃ¡rio A**.

---

## âœ… DependÃªncias e pontos de verificaÃ§Ã£o

- **Prometheus** (kubeâ€‘prometheusâ€‘stack) deve estar ativo no namespace `agrosolutions-observability`.
- **ServiceMonitor** aplicado no cluster:

```bash
kubectl get servicemonitors -n agrosolutions-observability
```

- **URLs locais principais**:
  - Grafana: [http://localhost:3000](http://localhost:3000)
  - Prometheus: [http://localhost:9090](http://localhost:9090)

---

## â„¹ï¸ Troubleshooting rÃ¡pido

- **Dashboard vazio**: verifique se as APIs estÃ£o rodando e expondo `/metrics`.
- **Targets DOWN**: confirme o label `monitoring: enabled` nos Services e o ServiceMonitor aplicado.
- **Sem dados de latÃªncia/RPS**: gere trÃ¡fego nas APIs (ex.: simulador ou chamadas via Swagger).

---

## ?? Rastreamento Distribuído (Distributed Tracing)

O rastreamento distribuído permite acompanhar o ciclo de vida de uma requisição que perpassa diversos serviços. Utilizamos **OpenTelemetry** para instrumentação e **Jaeger** para visualização.

### 1. Acessando a Interface do Jaeger

O Jaeger UI é o local onde você pode visualizar os traces.

Para acessar localmente, faça o port-forward do serviço do Jaeger (que roda no namespace grosolutions-local):

\\\ash
kubectl port-forward svc/jaeger-collector 16686:16686 -n agrosolutions-local
\\\

Em seguida, acesse no navegador: **[http://localhost:16686](http://localhost:16686)**

### 2. Gerando e Visualizando Traces

1.  **Gere Tráfego**: Utilize o Simulador ou faça chamadas aos endpoints da Ingestao.WebApi.
2.  **Busque no Jaeger**:
    *   No menu esquerdo 'Service', selecione \AgroSolutions.Ingestao.WebApi\ (ou outro serviço).
    *   Clique em **Find Traces**.
    *   Você verá uma lista de requisições. Clique em uma para ver o detalhe.
3.  **Trace Distribuído**: Se a requisição envolver múltiplos serviços, você verá as 'spans' de cada serviço aninhadas, permitindo identificar gargalos de latência.

### 3. Validação

Certifique-se que o serviço \jaeger\ está rodando:

\\\ash
kubectl get pods -l app=jaeger -n agrosolutions-local
\\\

Se não houver traços, verifique se a variável de ambiente \OpenTelemetry__Enabled\ está como 'true' e se o endpoint \http://jaeger-collector:4317\ está acessível pelos pods.


---

## ğŸ› ï¸ AutomaÃ§Ã£o e Dashboard-as-Code

A infraestrutura do Grafana neste projeto foi automatizada para carregar Data Sources e Dashboards via cÃ³digo.

### ğŸ” Credenciais de Acesso (Admin)

Caso utilize a implantaÃ§Ã£o customizada (via manifestos em `infra/k8s`):
- **UsuÃ¡rio**: `admin`
- **Senha**: `admin`

Para recuperar as credenciais via Secret:
```bash
kubectl get secret grafana-admin-credentials -o jsonpath="{.data.admin-user}" | base64 --decode
kubectl get secret grafana-admin-credentials -o jsonpath="{.data.admin-password}" | base64 --decode
```

### â• Gerenciamento de Dashboards

Os dashboards sÃ£o carregados automaticamente atravÃ©s de ConfigMaps monitorados por um Sidecar.

**Para adicionar um novo dashboard:**
1. Adicione o arquivo JSON do dashboard na pasta: `infra/k8s/base/observability/grafana/dashboards/`.
2. O Kustomize (`infra/k8s/base/observability/grafana/kustomization.yaml`) estÃ¡ configurado para gerar um ConfigMap com a label `grafana_dashboard: "1"` para os arquivos nesta pasta. *Nota: Se adicionar novos arquivos, lembre-se de listÃ¡-los no kustomization.yaml*.
3. Aplique a configuraÃ§Ã£o: `kubectl apply -k infra/k8s/base/observability`
4. O Grafana detectarÃ¡ a mudanÃ§a e disponibilizarÃ¡ o dashboard imediatamente na pasta "AgroSolutions" (sem necessidade de restart).
